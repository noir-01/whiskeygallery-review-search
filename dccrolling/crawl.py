# -*- coding: utf-8 -*-
import requests
from urllib import request
from bs4 import BeautifulSoup
from datetime import datetime,timedelta
import time
import pymysql
import mysql_auth
from multiprocessing import Pool,Manager
manager = Manager()
dataList = manager.list()   #multiprocessing ÏúÑÌïú Ï†ÑÏó≠Î≥ÄÏàò Î¶¨Ïä§Ìä∏

from sqlUpload import sqlUpload

login = mysql_auth.Info
#if ÎÇ†Ïßú Ï°∞Í±¥ ÏïàÎßûÏúºÎ©¥ page Í∞í +=1 Ìï¥ÏÑú Î¶¨ÌÑ¥
#inputDate = 'yyyy-mm-dd'

def crawlByPage(inputID,liquor,category):
    global dataList

    subject_str_dict = {
        "other": "Í∏∞ÌÉÄÎ¶¨Í∏∞ÌÉÄÎ¶¨Î∑∞",
        "whiskey": "Î¶¨Î∑∞üìù",
        "beer": "Î¶¨Î∑∞",
        "brandy":"Î¶¨Î∑∞",
    }
    subject_str = subject_str_dict[category]

    # URL
    BASE_URL = "https://gall.dcinside.com/mgallery/board/lists/?id=" + liquor + "&page=" #Ïà† Ï¢ÖÎ•òÏôÄ pageÍ∞íÏù¥ ÎπÑÏñ¥ÏûàÎã§.
    Domain_URL = "https://gall.dcinside.com"

    # Ìó§Îçî ÏÑ§Ï†ï
    headers = {'User-Agent' : 'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:100.0) Gecko/20100101 Firefox/100.0'},

    page = 1
    while True:
        time.sleep(0.001)   #Î∂ÄÌïò ÎßâÍ∏∞ ÏúÑÌï¥ time.sleep() ÏÇΩÏûÖ.
        # html
        response = requests.get(BASE_URL+str(page), headers=headers[0])
        soup = BeautifulSoup(response.content, 'html.parser')
        html_list = soup.find('tbody').find_all('tr')
        for i in html_list:
            #Í∏ÄÎ≤àÌò∏
            id = int(i.find('td', class_='gall_num').text)
            #ÎßêÎ®∏Î¶¨
            subject = i.find('td', class_='gall_subject').text
            # Ï†úÎ™©
            title = i.find('a', href=True).text

            #URL
            url = Domain_URL + i.find('a',href=True)['href']

            # ÎÇ†Ïßú Ï∂îÏ∂ú
            date_tag = i.find('td', class_='gall_date')
            date_dict = date_tag.attrs

            if len(date_dict) == 2:
                postDate = date_dict['title'][:10]
                postTime = date_dict['title'][11:]

            else:
                postDate =  date_tag.text

            """
            # Ï°∞Ìöå Ïàò Ï∂îÏ∂ú
            views_tag = i.find('td', class_='gall_count')
            view = views_tag.text
            """

            # Ï∂îÏ≤ú Ïàò Ï∂îÏ∂ú
            recommend_tag = i.find('td', class_='gall_recommend')
            recom = recommend_tag.text

            # ÎåìÍ∏Ä Ïàò Ï∂îÏ∂ú

            try:
                reply_tag = i.span.string.text
                if reply_tag[0] =='[':
                    reply = reply_tag.replace('[','')
                    reply = reply.replace(']','')
                else:
                    reply = 0
                #ÏûëÏÑ±ÏûêÍ∞Ä [blabla]Ïùº Í≤ΩÏö∞ 0ÏúºÎ°ú Î∞îÍøà
                reply=int(reply)

            except:
                reply = 0

            #subjectÍ∞Ä Î¶¨Î∑∞ÏùºÎïå ÏóÖÎ°úÎìú
            if(subject==subject_str):
                print(id)
                dataList.append([id,title,url,recom,reply,postDate])
                #sqlUpload(id,title,url,recom,reply,postDate,category)

            if id == inputID:
                return   #lastID ÎÇòÏò§Î©¥ Î∞òÎ≥µÎ¨∏ ÌÉàÏ∂ú

        page+=1

#cronÏùÑ Ïù¥Ïö©Ìï¥ 1ÏãúÍ∞ÑÎßàÎã§ ÏóÖÎ°úÎìúÌïòÍ∏∞
#findLastIDÌï®Ïàò: ÌòÑÏû¨ mysqlÏÉÅÏóêÏÑú Í∞ÄÏû• ÏµúÍ∑º Í∏ÄÏùò idÎ•º return Ìï® => Í∑∏ Í∏Ä Ï†ÑÍπåÏßÄ Î¶¨Î∑∞ ÏóÖÎ°úÎìú ÌïòÎ©¥ Îê®.
def findLastID(category):

    page = 1
    conn = pymysql.connect(
        host=login['host'],
        user=login['user'],
        password=login['password'],
        db=login['db'],
        charset=login['charset']
    )
    cursor = conn.cursor()
    sql = "select max(id) from " + category + "Review"
    cursor.execute(sql)
    lastID = cursor.fetchall()[0][0]
    conn.close()

    return lastID

def crawl(category):
    global dataList
    lastID = findLastID(category)
    print("Last Uploaded ID: ",lastID)
    if category=="whiskey" or category=="other":
        crawlByPage(lastID,"whiskey",category)
    else:
        crawlByPage(lastID, category, category)
    
    sqlUpload(dataList,category)
    dataList=manager.list()  #dataList Ï¥àÍ∏∞Ìôî

crawl("whiskey")
crawl("other")
crawl("brandy")
crawl("beer")
#category = other, brandy, beer, whiskey
# lastID = findLastID("whiskey")
# crawlByPage(lastID,"whiskey","whiskey")
# time.sleep(0.001)

# lastID = findLastID("other")
# crawlByPage(lastID,"whiskey","other")
# time.sleep(0.001)

# lastID = findLastID("beer")
# crawlByPage(lastID,"beer","beer")
# time.sleep(0.001)

# lastID = findLastID("brandy")
# crawlByPage(lastID,"brandy","brandy")
# time.sleep(0.001)

#crawlByPage("2022-12-04","whiskey","whiskey")